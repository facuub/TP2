{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "resultado_anterior = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(model, features, labels, usarCrossValidation=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if usarCrossValidation:\n",
    "        parametros = model.get_xgb_params()\n",
    "        dmatrix = xgb.DMatrix(features.values, label=labels.values)\n",
    "        cvresult = xgb.cv(parametros, dmatrix, num_boost_round=model.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                          metrics='auc', verbose_eval=True, early_stopping_rounds=early_stopping_rounds)\n",
    "        model.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    model.fit(features, labels,eval_metric='auc')\n",
    "    \n",
    "def obtener_marca(serie_de_modelo,prefix=\"\"):\n",
    "    # La marca es siempre la primer palabra del modelo\n",
    "    r = []\n",
    "    for modelo in serie_de_modelo.tolist():\n",
    "        if pd.isna(modelo):\n",
    "            r.append(\"Unknown\")\n",
    "        else:\n",
    "            r.append(prefix + modelo.split()[0])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('events_up_to_01062018.csv', low_memory = False, parse_dates = ['timestamp'], infer_datetime_format = True,\n",
    "                    dtype = {'event': 'category','condition': 'category','storage': 'category', 'color': 'category', 'staticpage': 'category', 'campaign_source': 'category', 'search_engine': 'category', 'channel': 'category', 'new_vs_returning': 'category', 'region': 'category', 'country': 'category', 'device_type': 'category'})\n",
    "labels = pd.read_csv('labels_training_set.csv', low_memory = False).set_index('person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "###                               CREACION DF PREDICTOR\n",
    "#\n",
    "\n",
    "dfPredictor = pd.DataFrame(df['person'].unique())\n",
    "dfPredictor.columns = ['person']\n",
    "dfPredictor = dfPredictor.set_index('person')\n",
    "\n",
    "#\n",
    "###                               FILTRADO DE FECHAS\n",
    "#\n",
    "\n",
    "antesDeMayo = df.loc[df['timestamp'] < pd.to_datetime('01-05-2018')]\n",
    "ult30Dias = df.loc[(df['timestamp'] > pd.to_datetime('01-05-2018'))]# & (df['timestamp'] > pd.to_datetime('15-05-2018'))]\n",
    "ult15Dias = df.loc[(df['timestamp'] > pd.to_datetime('15-05-2018'))]# & (df['timestamp'] > pd.to_datetime('25-05-2018'))]\n",
    "ult5Dias = df.loc[(df['timestamp'] > pd.to_datetime('25-05-2018'))]# & (df['timestamp'] > pd.to_datetime('31-05-2018'))]\n",
    "ultDia = df.loc[df['timestamp'] > pd.to_datetime('31-05-2018')]\n",
    "\n",
    "#\n",
    "###                               CREACION DE FEATURES\n",
    "#\n",
    "\n",
    "#\n",
    "##  POR EVENTO\n",
    "\n",
    "\n",
    "#  CHECKOUTS\n",
    "\n",
    "checkoutsPorPersonaAntesDeMayo = antesDeMayo.loc[antesDeMayo['event'] == 'checkout']['person'].value_counts().to_frame()\n",
    "checkoutsPorPersonaAntesDeMayo.columns = ['checkoutsPorPersonaAntesDeMayo']\n",
    "\n",
    "checkoutsPorPersonaUlt30Dias = ult30Dias.loc[ult30Dias['event'] == 'checkout']['person'].value_counts().to_frame()\n",
    "checkoutsPorPersonaUlt30Dias.columns = ['checkoutsUlt30Dias']\n",
    "\n",
    "checkoutsPorPersonaUlt15Dias = ult15Dias.loc[ult15Dias['event'] == 'checkout']['person'].value_counts().to_frame()\n",
    "checkoutsPorPersonaUlt15Dias.columns = ['checkoutsUlt15Dias']\n",
    "\n",
    "checkoutsPorPersonaUlt5Dias = ult5Dias.loc[ult5Dias['event'] == 'checkout']['person'].value_counts().to_frame()\n",
    "checkoutsPorPersonaUlt5Dias.columns = ['checkoutsUlt5Dias']\n",
    "\n",
    "checkoutsPorPersonaUltDia = ultDia.loc[ultDia['event'] == 'checkout']['person'].value_counts().to_frame()\n",
    "checkoutsPorPersonaUltDia.columns = ['checkoutsUltDia']\n",
    "\n",
    "\n",
    "dfPredictor = dfPredictor.join(checkoutsPorPersonaAntesDeMayo, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(checkoutsPorPersonaUlt30Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(checkoutsPorPersonaUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(checkoutsPorPersonaUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(checkoutsPorPersonaUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#  CONVERSIONES\n",
    "\n",
    "conversionesPorPersonaAntesDeMayo = antesDeMayo.loc[antesDeMayo['event'] == 'checkout']['person'].value_counts().to_frame()\n",
    "conversionesPorPersonaAntesDeMayo.columns = ['conversionesPorPersonaAntesDeMayo']\n",
    "\n",
    "conversionesPorPersonaUlt30Dias = ult30Dias.loc[ult30Dias['event'] == 'conversion']['person'].value_counts().to_frame()\n",
    "conversionesPorPersonaUlt30Dias.columns = ['conversionesUlt30Dias']\n",
    "\n",
    "conversionesPorPersonaUlt15Dias = ult15Dias.loc[ult15Dias['event'] == 'conversion']['person'].value_counts().to_frame()\n",
    "conversionesPorPersonaUlt15Dias.columns = ['conversionesUlt15Dias']\n",
    "\n",
    "conversionesPorPersonaUlt5Dias = ult5Dias.loc[ult5Dias['event'] == 'conversion']['person'].value_counts().to_frame()\n",
    "conversionesPorPersonaUlt5Dias.columns = ['conversionesUlt5Dias']\n",
    "\n",
    "conversionesPorPersonaUltDia = ultDia.loc[ultDia['event'] == 'conversion']['person'].value_counts().to_frame()\n",
    "conversionesPorPersonaUltDia.columns = ['conversionesUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(conversionesPorPersonaAntesDeMayo, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(conversionesPorPersonaUlt30Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(conversionesPorPersonaUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(conversionesPorPersonaUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(conversionesPorPersonaUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#  VISITAS\n",
    "\n",
    "visitasUlt15DiasPorPersona = ult15Dias.loc[ult15Dias['event'] == 'visited site']['person'].value_counts().to_frame()\n",
    "visitasUlt15DiasPorPersona.columns = ['CantVisitasUlt15Dias']\n",
    "\n",
    "visitasUlt5DiasPorPersona = ult5Dias.loc[ult5Dias['event'] == 'visited site']['person'].value_counts().to_frame()\n",
    "visitasUlt5DiasPorPersona.columns = ['CantVisitasUlt5Dias']\n",
    "\n",
    "visitasUltDiaPorPersona = ultDia.loc[ultDia['event'] == 'visited site']['person'].value_counts().to_frame()\n",
    "visitasUltDiaPorPersona.columns = ['CantVisitasUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(visitasUlt15DiasPorPersona, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(visitasUlt5DiasPorPersona, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(visitasUltDiaPorPersona, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#  VIEWED PRODUCT\n",
    "\n",
    "viewedProductPorPersonaUlt15Dias = ult15Dias.loc[ult15Dias['event'] == 'viewed product']['person'].value_counts().to_frame()\n",
    "viewedProductPorPersonaUlt15Dias.columns = ['viewedProductUlt15Dias']\n",
    "\n",
    "viewedProductPorPersonaUlt5Dias = ult5Dias.loc[ult5Dias['event'] == 'viewed product']['person'].value_counts().to_frame()\n",
    "viewedProductPorPersonaUlt5Dias.columns = ['viewedProductUlt5Dias']\n",
    "\n",
    "viewedProductPorPersonaUltDia = ultDia.loc[ultDia['event'] == 'viewed product']['person'].value_counts().to_frame()\n",
    "viewedProductPorPersonaUltDia.columns = ['viewedProductUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(viewedProductPorPersonaUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(viewedProductPorPersonaUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(viewedProductPorPersonaUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#\n",
    "### POR CANAL DE ORIGEN\n",
    "\n",
    "visitasUlt30Dias = ult30Dias.loc[ult30Dias['event'] == 'visited site']\n",
    "visitasUlt15Dias = ult15Dias.loc[ult15Dias['event'] == 'visited site']\n",
    "visitasUlt5Dias = ult5Dias.loc[ult5Dias['event'] == 'visited site']\n",
    "visitasUltDia = ultDia.loc[ultDia['event'] == 'visited site']\n",
    "\n",
    "#  PAGO\n",
    "\n",
    "paidUlt15Dias = visitasUlt15Dias.loc[visitasUlt15Dias['channel'] == 'Paid']['person'].value_counts().to_frame()\n",
    "paidUlt15Dias.columns = ['CanalPagoUlt15Dias']\n",
    "\n",
    "paidUlt5Dias = visitasUlt5Dias.loc[visitasUlt5Dias['channel'] == 'Paid']['person'].value_counts().to_frame()\n",
    "paidUlt5Dias.columns = ['CanalPagoUlt5Dias']\n",
    "\n",
    "paidUltDia = visitasUltDia.loc[visitasUltDia['channel'] == 'Paid']['person'].value_counts().to_frame()\n",
    "paidUltDia.columns = ['CanalPagoUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(paidUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(paidUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(paidUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#  ORGANIC\n",
    "\n",
    "organicUlt15Dias = visitasUlt15Dias.loc[visitasUlt15Dias['channel'] == 'Organic']['person'].value_counts().to_frame()\n",
    "organicUlt15Dias.columns = ['CanalOrganicoUlt15Dias']\n",
    "\n",
    "organicUlt5Dias = visitasUlt5Dias.loc[visitasUlt5Dias['channel'] == 'Organic']['person'].value_counts().to_frame()\n",
    "organicUlt5Dias.columns = ['CanalOrganicoUlt5Dias']\n",
    "\n",
    "organicUltDia = visitasUltDia.loc[visitasUltDia['channel'] == 'Organic']['person'].value_counts().to_frame()\n",
    "organicUltDia.columns = ['CanalOrganicoUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(organicUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(organicUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(organicUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#  DIRECT\n",
    "directUlt30Dias = visitasUlt30Dias.loc[visitasUlt30Dias['channel'] == 'Direct']['person'].value_counts().to_frame()\n",
    "directUlt30Dias.columns = ['CanalDirectoUlt30Dias']\n",
    "\n",
    "directUlt15Dias = visitasUlt15Dias.loc[visitasUlt15Dias['channel'] == 'Direct']['person'].value_counts().to_frame()\n",
    "directUlt15Dias.columns = ['CanalDirectoUlt15Dias']\n",
    "#directUlt15Dias['CanalDirectoUlt15Dias'] = 1\n",
    "\n",
    "directUlt5Dias = visitasUlt5Dias.loc[visitasUlt5Dias['channel'] == 'Direct']['person'].value_counts().to_frame()\n",
    "directUlt5Dias.columns = ['CanalDirectoUlt5Dias']\n",
    "\n",
    "directUltDia = visitasUltDia.loc[visitasUltDia['channel'] == 'Direct']['person'].value_counts().to_frame()\n",
    "directUltDia.columns = ['CanalDirectoUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(directUlt30Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(directUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(directUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(directUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#  REFERRAL\n",
    "\n",
    "referralUlt15Dias = visitasUlt15Dias.loc[visitasUlt15Dias['channel'] == 'Referral']['person'].value_counts().to_frame()\n",
    "referralUlt15Dias.columns = ['CanalReferidoUlt15Dias']\n",
    "\n",
    "referralUlt5Dias = visitasUlt5Dias.loc[visitasUlt5Dias['channel'] == 'Referral']['person'].value_counts().to_frame()\n",
    "referralUlt5Dias.columns = ['CanalReferidoUlt5Dias']\n",
    "\n",
    "referralUltDia = visitasUltDia.loc[visitasUltDia['channel'] == 'Referral']['person'].value_counts().to_frame()\n",
    "referralUltDia.columns = ['CanalReferidoUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(referralUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(referralUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(referralUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#  SOCIAL\n",
    "\n",
    "socialUlt15Dias = visitasUlt15Dias.loc[visitasUlt15Dias['channel'] == 'Social']['person'].value_counts().to_frame()\n",
    "socialUlt15Dias.columns = ['CanalSocialUlt15Dias']\n",
    "\n",
    "socialUlt5Dias = visitasUlt5Dias.loc[visitasUlt5Dias['channel'] == 'Social']['person'].value_counts().to_frame()\n",
    "socialUlt5Dias.columns = ['CanalSocialUlt5Dias']\n",
    "\n",
    "socialUltDia = visitasUltDia.loc[visitasUltDia['channel'] == 'Social']['person'].value_counts().to_frame()\n",
    "socialUltDia.columns = ['CanalSocialUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(socialUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(socialUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(socialUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#  EMAIL\n",
    "\n",
    "emailUlt15Dias = visitasUlt15Dias.loc[visitasUlt15Dias['channel'] == 'Email']['person'].value_counts().to_frame()\n",
    "emailUlt15Dias.columns = ['CanalEmailUlt15Dias']\n",
    "\n",
    "emailUlt5Dias = visitasUlt5Dias.loc[visitasUlt5Dias['channel'] == 'Email']['person'].value_counts().to_frame()\n",
    "emailUlt5Dias.columns = ['CanalEmailUlt5Dias']\n",
    "\n",
    "emailUltDia = visitasUltDia.loc[visitasUltDia['channel'] == 'Email']['person'].value_counts().to_frame()\n",
    "emailUltDia.columns = ['CanalEmailUltDia']\n",
    "\n",
    "dfPredictor = dfPredictor.join(emailUlt15Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(emailUlt5Dias, how = 'left', on = 'person').fillna(value = 0)\n",
    "dfPredictor = dfPredictor.join(emailUltDia, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "#\n",
    "### FEATURES AVANZADOS\n",
    "\n",
    "#  CANTIDAD DE CHECKOUTS POR MARCA\n",
    "\n",
    "#marcas = {'Samsung':'Samsung', 'Motorola':'Motorola', 'iPhone':'iPhone', 'LG':'LG', 'Sony':'Sony', 'Lenovo':'Lenovo','iPad':'iPad', 'Quantum':'Quantum', 'Asus':'Asus'}\n",
    "prefijo = \"total_checks_\"\n",
    "#marcas = {marca: prefijo + nombreFeature for marca, nombreFeature in marcas.items()}\n",
    "\n",
    "total_checks = df.loc[df[\"event\"]==\"checkout\"].copy()\n",
    "total_checks[\"Marca\"] = obtener_marca(total_checks[\"model\"],prefijo)\n",
    "#total_checks = total_checks.loc[(total_checks[\"Marca\"]==marcas[\"iPhone\"])|(total_checks[\"Marca\"]==marcas[\"Samsung\"])]\n",
    "total_checks[\"contador\"] = 1\n",
    "total_checks=total_checks.loc[:,[\"Marca\",\"person\",\"contador\"]].groupby([\"person\",\"Marca\"]).agg({\"contador\":\"sum\"}).reset_index()\\\n",
    "    .pivot(columns='Marca', index='person', values='contador').fillna(0)\n",
    "dfPredictor = dfPredictor.join(total_checks, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "prefijo = \"total_views_\"\n",
    "total_views = ult30Dias.loc[ult30Dias[\"event\"]==\"viewed product\"].copy()\n",
    "total_views[\"Marca\"] = obtener_marca(total_views[\"model\"],prefijo)\n",
    "#total_views = total_views.loc[(total_views[\"Marca\"]==marcas[\"iPhone\"])|(total_views[\"Marca\"]==marcas[\"Samsung\"])]\n",
    "total_views[\"contador\"] = 1\n",
    "total_views=total_views.loc[:,[\"Marca\",\"person\",\"contador\"]].groupby([\"person\",\"Marca\"]).agg({\"contador\":\"sum\"}).reset_index()\\\n",
    "    .pivot(columns='Marca', index='person', values='contador').fillna(0)\n",
    "dfPredictor = dfPredictor.join(total_views, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "## CANTIDAD DE BUSQUEADAS\n",
    "name_feature1 = \"cant_searchs_ult_30\"\n",
    "name_feature2 = \"busco_ult_30\"\n",
    "cant_search = ult30Dias.loc[ult30Dias[\"event\"]== \"searched products\",[\"person\",\"search_term\"]]\n",
    "cant_search = cant_search[pd.notnull(cant_search['search_term'])]\n",
    "cant_search[name_feature1] = 1\n",
    "cant_search = cant_search.groupby(\"person\").agg(\"sum\")\n",
    "cant_search[name_feature2] = [bool(x) for x in cant_search[name_feature1]]\n",
    "dfPredictor = dfPredictor.join(cant_search, how = 'left', on = 'person')\n",
    "dfPredictor[name_feature1].fillna(value = 0,inplace=True)\n",
    "dfPredictor[name_feature2].fillna(value = False,inplace=True)\n",
    "\n",
    "name_feature1 = \"cant_searchs_ult_15\"\n",
    "name_feature2 = \"busco_ult_15\"\n",
    "cant_search = ult15Dias.loc[ult15Dias[\"event\"]== \"searched products\",[\"person\",\"search_term\"]]\n",
    "cant_search = cant_search[pd.notnull(cant_search['search_term'])]\n",
    "cant_search[name_feature1] = 1\n",
    "cant_search = cant_search.groupby(\"person\").agg(\"sum\")\n",
    "cant_search[name_feature2] = [bool(x) for x in cant_search[name_feature1]]\n",
    "dfPredictor = dfPredictor.join(cant_search, how = 'left', on = 'person')\n",
    "dfPredictor[name_feature1].fillna(value = 0,inplace=True)\n",
    "dfPredictor[name_feature2].fillna(value = False,inplace=True)\n",
    "\n",
    "name_feature1 = \"cant_searchs_ult_5\"\n",
    "name_feature2 = \"busco_ult_5\"\n",
    "cant_search = ult5Dias.loc[ult5Dias[\"event\"]== \"searched products\",[\"person\",\"search_term\"]]\n",
    "cant_search = cant_search[pd.notnull(cant_search['search_term'])]\n",
    "cant_search[name_feature1] = 1\n",
    "cant_search = cant_search.groupby(\"person\").agg(\"sum\")\n",
    "cant_search[name_feature2] = [bool(x) for x in cant_search[name_feature1]]\n",
    "dfPredictor = dfPredictor.join(cant_search, how = 'left', on = 'person')\n",
    "dfPredictor[name_feature1].fillna(value = 0,inplace=True)\n",
    "dfPredictor[name_feature2].fillna(value = False,inplace=True)\n",
    "\n",
    "name_feature1 = \"cant_searchs_total\"\n",
    "name_feature2 = \"busco_total\"\n",
    "cant_search = df.loc[df[\"event\"]== \"searched products\",[\"person\",\"search_term\"]]\n",
    "cant_search = cant_search[pd.notnull(cant_search['search_term'])]\n",
    "cant_search[name_feature1] = 1\n",
    "cant_search = cant_search.groupby(\"person\").agg(\"sum\")\n",
    "cant_search[name_feature2] = [bool(x) for x in cant_search[name_feature1]]\n",
    "dfPredictor = dfPredictor.join(cant_search, how = 'left', on = 'person')\n",
    "dfPredictor[name_feature1].fillna(value = 0,inplace=True)\n",
    "dfPredictor[name_feature2].fillna(value = False,inplace=True)\n",
    "\n",
    "# Primer ingreso\n",
    "tiempo_prom = df.loc[(df['event']!='ad campaign hit') & (df['event']!='search engine hit'),[\"person\",\"timestamp\"]]\n",
    "tiempo_prom = tiempo_prom.groupby(\"person\").agg({\"timestamp\":\"min\"})\n",
    "tiempo_prom[\"first\"] = (pd.to_datetime(\"2018-06-01\")-tiempo_prom[\"timestamp\"]).dt.days\n",
    "del tiempo_prom['timestamp']\n",
    "tiempo_prom\n",
    "dfPredictor = dfPredictor.join(tiempo_prom, how = 'left', on = 'person')\n",
    "dfPredictor[\"first\"].fillna(value = 180,inplace=True)\n",
    "\n",
    "# region desde donde mas visita\n",
    "region = df.loc[(df[\"event\"] == \"visited site\") & (df['country'] == 'Brazil'), ['person','region']]\n",
    "region = region\n",
    "region[\"count\"] =1\n",
    "region = region.groupby([\"person\",\"region\"]).agg({\"count\":\"count\"}).reset_index()\\\n",
    "    .sort_values('count', ascending=False).drop_duplicates(\"person\")\n",
    "del region[\"count\"]\n",
    "region.set_index(\"person\",inplace=True)\n",
    "regionesNoBrasil = df.loc[(df[\"event\"] == \"visited site\") & (df['country'] != 'Brazil')]['region'].unique()\n",
    "region['region'].cat.remove_categories(regionesNoBrasil,inplace=True)\n",
    "region = pd.get_dummies(region['region'])\n",
    "dfPredictor = dfPredictor.join(region, how = 'left', on = 'person').fillna(value = 0)\n",
    "\n",
    "\n",
    "# Pais\n",
    "pais = df.loc[df[\"event\"] == \"visited site\", ['person','country']]\n",
    "pais[\"count\"] =1\n",
    "pais = pais.groupby([\"person\",\"country\"]).agg({\"count\":\"count\"}).reset_index()\\\n",
    "    .sort_values('count', ascending=False).drop_duplicates(\"person\")\n",
    "del pais[\"count\"]\n",
    "pais[\"esDeBrasil\"] = pais[\"country\"] == \"Brazil\"\n",
    "del pais[\"country\"]\n",
    "pais.set_index(\"person\",inplace=True)\n",
    "dfPredictor = dfPredictor.join(pais, how = 'left', on = 'person')\n",
    "dfPredictor[\"esDeBrasil\"].fillna(value = False,inplace=True)\n",
    "\n",
    "#vieron\n",
    "vieron_celular = df.loc[(df[\"event\"] == \"viewed product\") & (df[\"model\"] == \"Samsung Galaxy J5\"),[\"person\"]]\n",
    "vieron_celular[\"vieron_celular\"] = 1\n",
    "vieron_celular.set_index(\"person\",inplace=True)\n",
    "vieron_celular = vieron_celular[~vieron_celular.index.duplicated(keep='first')]\n",
    "dfPredictor = dfPredictor.join(vieron_celular, how = 'left', on = 'person')\n",
    "dfPredictor[\"vieron_celular\"].fillna(value = 0,inplace=True)\n",
    "\n",
    "### TEEEEEEEEEEST Cuantas veces hizo checkout de los 20 celus mas visitados\n",
    "view_products = ult15Dias.loc[ult15Dias[\"event\"] == \"checkout\",[\"model\"]].copy()\n",
    "view_products[\"Visitas\"] = 1\n",
    "phones20view = view_products.groupby(by=[\"model\"]).agg(\"sum\").sort_values(by=\"Visitas\",ascending=False).head(4).index.tolist()\n",
    "checkouts = df.loc[df[\"event\"]==\"checkout\",[\"person\",\"model\"]].copy()\n",
    "def estaDentroDe(serie,lista):\n",
    "    r = []\n",
    "    for i in serie:\n",
    "        if i in lista:\n",
    "            r.append(True)\n",
    "        else:\n",
    "            r.append(False)\n",
    "    return r\n",
    "checkouts[\"model\"] = estaDentroDe(checkouts[\"model\"],phones20view)\n",
    "checkouts= checkouts.groupby(\"person\").agg(\"sum\")\n",
    "dfPredictor = dfPredictor.join(checkouts, how = 'left', on = 'person')\n",
    "dfPredictor[\"model\"].fillna(value = 0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregado y quitado de features y cambio de disposicion de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(dfPredictor.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio disposicion de columnas ya que esta presenta mejor resultado\n",
    "# Cuando se agregue una feature nueva, agregar el nombre de columna a esta lista para que surta efecto\n",
    "# Reordenar en la lista cambia el orden de las columnas en el predictor\n",
    "\n",
    "cols = [\n",
    "'CanalDirectoUlt15Dias',\n",
    "'checkoutsUlt15Dias',\n",
    "'checkoutsUlt30Dias',\n",
    "'checkoutsUlt5Dias',\n",
    "'checkoutsUltDia',\n",
    "'conversionesUlt30Dias',\n",
    "'conversionesUlt15Dias',\n",
    "'conversionesUlt5Dias',\n",
    "'conversionesUltDia',\n",
    "'CantVisitasUlt15Dias',\n",
    "'CantVisitasUlt5Dias',\n",
    "'CantVisitasUltDia',\n",
    "'viewedProductUlt15Dias',\n",
    "'viewedProductUlt5Dias',\n",
    "'viewedProductUltDia',\n",
    "'CanalOrganicoUlt5Dias',\n",
    "'CanalDirectoUlt5Dias',\n",
    "'CanalDirectoUltDia',\n",
    "'CanalReferidoUlt15Dias',\n",
    "'CanalReferidoUlt5Dias',\n",
    "'CanalReferidoUltDia',\n",
    "'total_checks_Samsung',\n",
    "'total_checks_iPhone',\n",
    "'cant_searchs_ult_15',\n",
    "#'CanalPagoUlt5Dias',\n",
    "#'total_views_Samsung',\n",
    "#'total_views_iPhone',\n",
    "#'total_checks_Motorola',\n",
    "#'total_views_Motorola',\n",
    "#'CanalDirectoUlt30Dias'\n",
    "#'total_views_Asus',\n",
    "#'total_views_LG',\n",
    "#'total_views_Lenovo',\n",
    "#'total_views_Quantum',\n",
    "#'total_views_Sony',\n",
    "#'total_views_iPad',\n",
    "#'total_checks_Asus',\n",
    "#'total_checks_LG',\n",
    "#'total_checks_Lenovo',\n",
    "#'total_checks_Quantum',\n",
    "#'total_checks_Sony',\n",
    "#'checkoutsPorPersonaAntesDeMayo',\n",
    "#'conversionesPorPersonaAntesDeMayo',\n",
    "#'CanalPagoUlt15Dias',\n",
    "#'CanalPagoUltDia',\n",
    "#'CanalOrganicoUlt15Dias',\n",
    "#'CanalOrganicoUltDia',\n",
    "#'CanalSocialUlt15Dias',\n",
    "#'CanalSocialUlt5Dias',\n",
    "#'CanalSocialUltDia',\n",
    "#'CanalEmailUlt15Dias',\n",
    "#'CanalEmailUlt5Dias',\n",
    "#'CanalEmailUltDia',\n",
    "#\"first\" \n",
    "#'cant_searchs_ult_30',\n",
    "#'busco_ult_30',\n",
    "#'busco_ult_15',\n",
    "#'cant_searchs_ult_5',\n",
    "#'busco_ult_5', \n",
    "#'cant_searchs_total',\n",
    "#\"busco_total\"\n",
    "#\"region\",\n",
    "#'esDeBrasil',\n",
    "##\"vieron_celular\",\n",
    "#'Acre', 'Alagoas', 'Amapa', 'Amazonas', 'Bahia',\n",
    "#'Ceara', 'Espirito Santo', 'Federal District', 'Goias', 'Maranhao',\n",
    "#'Mato Grosso', 'Mato Grosso do Sul', 'Minas Gerais', 'Para', 'Parana',\n",
    "#'Para√≠ba', 'Pernambuco', 'Piaui', 'Rio Grande do Norte',\n",
    "#'Rio Grande do Sul', 'Rio de Janeiro', 'Rondonia', 'Roraima',\n",
    "#'Santa Catarina', 'Sao Paulo', 'Sergipe', 'Tocantins'\n",
    "]\n",
    "\n",
    "\n",
    "# Separo los labels locales\n",
    "dfPredictorIndexado=dfPredictor.reindex(columns=cols)\n",
    "#dfPredictorIndexado = dfPredictorIndexado.join(one_hot, how = 'left', on = 'person')\n",
    "dfPredictorLocal = dfPredictorIndexado.join(labels, how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dfPredictorLocal.iloc[:,:-1], dfPredictorLocal.iloc[:,-1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "modelo = xgb.XGBRegressor(\n",
    " #booster='dart',\n",
    " learning_rate =0.05,\n",
    " n_estimators=1000,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.4,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " nthread=-1,\n",
    " #sample_type='weighted',\n",
    " #rate_drop=0.05,\n",
    " #skip_dropout=0.3,\n",
    " random_state=27)\n",
    "\n",
    "modelfit(modelo, X_train, y_train, early_stopping_rounds=50)\n",
    "\n",
    "predsa = modelo.predict(X_test)\n",
    "resultado = roc_auc_score(y_test, predsa)\n",
    "print(resultado)\n",
    "\n",
    "print(\"Vario: {} con respecto al anterior\".format(resultado-resultado_anterior))\n",
    "resultado_anterior = resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion del submit para kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(modelo, X, y, early_stopping_rounds=50)\n",
    "kaggle = pd.read_csv('trocafone_kaggle_test.csv', low_memory = False)\n",
    "kaggle = kaggle.set_index('person')\n",
    "dfPredictorSubmit = dfPredictorIndexado.join(kaggle, how = 'inner')\n",
    "predsSubmit = modelo.predict(dfPredictorSubmit)\n",
    "predsSubmit[predsSubmit < 0 ] = 0\n",
    "predsSubmit[predsSubmit > 1] = 1\n",
    "dfPredictorSubmit['label'] = predsSubmit\n",
    "dfPredictorSubmit['label'].to_frame().to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest para feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "names = X.columns\n",
    "rf = RandomForestRegressor(\n",
    "    random_state=123,\n",
    "    n_estimators=400,\n",
    "    min_samples_split=3\n",
    ")\n",
    "rf.fit(X_train.values, y_train.values.ravel())\n",
    "impor = np.vstack((names, rf.feature_importances_)).T\n",
    "imporDf = pd.DataFrame(impor)\n",
    "imporDf.columns = ['feature', 'importancia']\n",
    "imporDf = imporDf.set_index('feature').sort_values(by=['importancia'], ascending=False).iloc[::-1]\n",
    "ax = imporDf.plot(kind='barh')\n",
    "ax.set_title(\"Importancia de cada feature segun Random Forests\")\n",
    "ax.set(xlabel=\"Importancia\", ylabel=\"Feature\")\n",
    "plt.figure(figsize=(10,10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
